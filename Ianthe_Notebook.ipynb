{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da4d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import napari\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "from scipy import stats\n",
    "import skimage as ski\n",
    "from bioio import BioImage\n",
    "import bioio_tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320b4df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum number of pixels for a filament to be included in analysis\n",
    "min_pixels = 3\n",
    "\n",
    "# Minimum length (um) for a filament to be included in analysis.\n",
    "# Can select 2D, 3D, or both.\n",
    "min_length_2D = 0\n",
    "min_length_3D = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b75bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_coordinates(coordinate_string, tuple_format=False):\n",
    "\tcoords_str = coordinate_string[1:-1]\n",
    "\tcoord_list = []\n",
    "\tfor match in re.findall(r\"\\(.*?\\)\", coords_str):\n",
    "\t\tcoordinate = match[1:-1]\n",
    "\t\tcoord_list.append([float(coord) for coord in coordinate.split(\",\")])\n",
    "\tif tuple_format:\n",
    "\t\treturn [tuple(coord) for coord in coord_list]\n",
    "\treturn np.array(coord_list)\n",
    "\n",
    "def parse_list(list_string):\n",
    "\tlist_str = list_string[1:-1]\n",
    "\treturn [int(item) for item in list_str.split(\",\")]\n",
    "\n",
    "def get_distance(point_array, dims=3):\n",
    "\tif dims == 2:\n",
    "\t\tpoint_array = point_array[:, :2]\n",
    "\tdiffs = np.diff(point_array, axis=0)\n",
    "\tdistances = np.linalg.norm(diffs, axis=1)\n",
    "\treturn np.sum(distances)\n",
    "\n",
    "def get_radians_2D(p1, p2):\n",
    "\tradians = math.atan2(p2[1] - p1[1], p2[0] - p1[0])\n",
    "\tabsolute_radians = np.mod(radians, np.pi)\n",
    "\treturn absolute_radians\n",
    "\n",
    "\n",
    "def get_average_radians(point_array, spacer=5):\n",
    "\tif spacer >= len(point_array):\n",
    "\t\tspacer = len(point_array) - 1\n",
    "\txdiff = point_array[spacer:, 0] - point_array[:-spacer, 0]\n",
    "\tydiff = point_array[spacer:, 1] - point_array[:-spacer, 1]\n",
    "\tradians = np.arctan2(ydiff, xdiff)\n",
    "\tmean_radians = stats.circmean(radians)\n",
    "\tabsolute_radians = np.mod(mean_radians, np.pi)\n",
    "\treturn absolute_radians\n",
    "\n",
    "def compareAngles(a, b):\n",
    "\tdelta = ((b - a + 180.0) % 360.0) - 180.0\n",
    "\treturn np.abs(delta)\n",
    "\n",
    "def get_branch_angles(df, vertices_col, angle_col, new_col):\n",
    "\t# Keep original order/id\n",
    "\ttmp = df.reset_index().rename(columns={\"index\": \"_idx\"})\n",
    "\n",
    "\t# 1) One vertex per row\n",
    "\tex = tmp[[\"_idx\", angle_col, vertices_col]].explode(vertices_col, ignore_index=True)\n",
    "\n",
    "\t# 2) Self-join on vertex to find neighbors sharing any vertex\n",
    "\tpairs = ex.merge(ex, on=vertices_col, how=\"inner\", suffixes=(\"_src\", \"_tgt\"))\n",
    "\n",
    "\t# 3) Drop self-pairs and (optionally) duplicate pairs that arise if two rows share multiple vertices\n",
    "\tpairs = pairs[pairs[\"_idx_src\"] != pairs[\"_idx_tgt\"]]\n",
    "\tpairs = pairs.drop_duplicates([\"_idx_src\", \"_idx_tgt\"])\n",
    "\n",
    "\t# 4) Vectorized angle diffs from src->tgt\n",
    "\tdiffs = compareAngles(pairs[f\"{angle_col}_src\"].to_numpy(),\n",
    "\t\t\t\t\t\t   pairs[f\"{angle_col}_tgt\"].to_numpy())\n",
    "\tpairs = pairs.assign(diff=diffs)\n",
    "\n",
    "\t# 5) Keep strictly positive diffs, aggregate per source row as list\n",
    "\tpairs = pairs[pairs[\"diff\"] > 0]\n",
    "\tagg = pairs.groupby(\"_idx_src\")[\"diff\"].apply(list).rename(new_col)\n",
    "\n",
    "\t# 6) Join back to original frame\n",
    "\tout = tmp.join(agg, on=\"_idx\").drop(columns=[\"_idx\"])\n",
    "\n",
    "\t# Preserve original index/columns order\n",
    "\tout.index = df.index\n",
    "\treturn out\n",
    "\n",
    "def get_residuals(point_array):\n",
    "\tNDModel = ski.measure.LineModelND()\n",
    "\tJustStartAndEnd = np.stack((point_array[0, :], point_array[-1, :]))\n",
    "\tNDModel.estimate(JustStartAndEnd)\n",
    "\treturn np.mean(NDModel.residuals(point_array))\n",
    "\n",
    "def get_curvature(coords, spacing=1):\n",
    "\tn = coords.shape[0]\n",
    "\tif n < (3 * spacing):\n",
    "\t\treturn np.nan, np.nan\n",
    "\txy = coords[:, :2]\n",
    "\n",
    "\tcurv = []\n",
    "\tfor i in range(spacing, n - spacing):\n",
    "\t\te1, p, e2 = xy[i - spacing], xy[i], xy[i + spacing]\n",
    "\t\tv1, v2 = p - e1, e2 - p\n",
    "\t\tl1, l2, l3 = np.linalg.norm(v1), np.linalg.norm(v2), np.linalg.norm(e2 - e1)\n",
    "\t\tdenom = l1 * l2 * l3\n",
    "\t\tif denom == 0:\n",
    "\t\t\tcontinue\n",
    "\t\tcross_z = v1[0] * v2[1] - v1[1] * v2[0]\n",
    "\t\tk = (abs(cross_z) / denom) * np.sign(cross_z)\n",
    "\t\tcurv.append(k)\n",
    "\n",
    "\tif not curv:\n",
    "\t\treturn np.nan, np.nan\n",
    "\n",
    "\tcurv = np.array(curv)\n",
    "\taccumulated_curv = np.nanmean(np.abs(curv))\n",
    "\tnet_curv = np.abs(np.nanmean(curv))\n",
    "\treturn accumulated_curv, net_curv\n",
    "\n",
    "def render_filaments(df, filename, viewer):\n",
    "\tonefile = df[df[\"Filename\"] == filename]\n",
    "\timp = BioImage(onefile[\"Filename\"][0], reader=bioio_tifffile.Reader)\n",
    "\timage_data = imp.data[0, 0, :, :, :]\n",
    "\tscale = (imp.physical_pixel_sizes.Z, imp.physical_pixel_sizes.Y, imp.physical_pixel_sizes.X)\n",
    "\tviewer.add_image(image_data, scale=scale)\n",
    "\tcoordlist = onefile[\"Coordinates (um)\"].tolist()\n",
    "\tlabel_img = np.zeros(image_data.shape, dtype=np.uint16)\n",
    "\tcoordlist = [np.round(coord[:, ::-1]/scale).astype(int) for coord in coordlist]\n",
    "\tfor label_id, coord in enumerate(coordlist):\n",
    "\t\tfor index in range(coord.shape[0]):\n",
    "\t\t\tlabel_img[(coord[index, 0], coord[index, 1], coord[index, 2])] = label_id + 1\n",
    "\tviewer.add_labels(label_img, scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea9e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input \"Per_Filament_Coordinates.csv\" filepath here\n",
    "folder_path = r\"D:\\Data\\Durham\\Output - Copy\"\n",
    "filename = \"Per_Filament_Coordinates.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c661ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads in data\n",
    "datafile = os.path.join(folder_path, filename)\n",
    "data = pd.read_csv(datafile)\n",
    "# Parses coordinate strings into numpy arrays\n",
    "data[\"Coordinates (um)\"] = data[\"Coordinates (um)\"].apply(parse_coordinates)\n",
    "data[\"Verticies\"] = data[\"Verticies\"].apply(parse_coordinates, tuple_format=True)\n",
    "# Parses vertex locations into lists\n",
    "data[\"Vertex Locations\"] = data[\"Vertex Locations\"].apply(parse_list)\n",
    "# Getting number of pixels in filament\n",
    "data[\"Num. Pixels\"] = data[\"Coordinates (um)\"].apply(lambda coords: len(coords))\n",
    "# Filtering by minimum pixels\n",
    "data = data[data[\"Num. Pixels\"] >= min_pixels]\n",
    "\n",
    "# Getting length of filament in 2D\n",
    "data[\"Length 2D (um)\"] = data[\"Coordinates (um)\"].apply(get_distance, dims=2)\n",
    "# Filtering by minimum lengths in 2D\n",
    "data = data[data[\"Length 2D (um)\"] >= min_length_2D]\n",
    "# Getting length of filament in 3D\n",
    "data[\"Length 3D (um)\"] = data[\"Coordinates (um)\"].apply(get_distance, dims=3)\n",
    "# Filtering by minimum lengths in 3D\n",
    "data = data[data[\"Length 3D (um)\"] >= min_length_3D]\n",
    "\n",
    "# Gets angles by getting angle between points spaced by 'spacer' value and averaging them\n",
    "data[\"Average Angle (radians)\"] = data[\"Coordinates (um)\"].apply(get_average_radians, spacer=5)\n",
    "data[\"Average Angle (degrees)\"] = np.degrees(data[\"Average Angle (radians)\"])\n",
    "# Gets angle between the first and last point of the filament\n",
    "data[\"End to End Angle (radians)\"] = data[\"Coordinates (um)\"].apply(lambda coords: get_radians_2D(coords[0], coords[-1]))\n",
    "data[\"End to End Angle (degrees)\"] = np.degrees(data[\"End to End Angle (radians)\"])\n",
    "\n",
    "# Gets branch angles by finding filaments that share verticies and comparing their average angles\n",
    "results = []\n",
    "for (fname, chan), subset in data.groupby([\"Filename\", \"Channel\"]):\n",
    "\tresults.append(get_branch_angles(subset, \"Verticies\", \"Average Angle (degrees)\", \"Branch Angles (degrees)\"))\n",
    "data = pd.concat(results)\n",
    "\n",
    "#  Gets the mean distance from a straight line between the endpoints of the filament\n",
    "data[\"Deviation (um)\"] = data[\"Coordinates (um)\"].apply(get_residuals)\n",
    "\n",
    "# Gets curvature values\n",
    "data[[\"Accumulated Curvature\", \"Net Curvature\"]] = data[\"Coordinates (um)\"].apply(lambda coords: get_curvature(coords, spacing=1)).apply(pd.Series)\n",
    "\n",
    "databackup = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "809954b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = databackup.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaff53a",
   "metadata": {},
   "source": [
    "This next cell saves the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e0b9525",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(os.path.join(folder_path, \"Per_Filament_Coordinates_Analyzed.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad1e70",
   "metadata": {},
   "source": [
    "This next cell can load in previously saved outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea9e0f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(os.path.join(folder_path, \"Per_Filament_Coordinates_Analyzed.pkl\"))\n",
    "databackup = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab6750",
   "metadata": {},
   "source": [
    "This next cell opens up napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92962a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "Viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325168f",
   "metadata": {},
   "source": [
    "This next cell allows you to view a labelled image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16445e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_filaments(data, data[\"Filename\"][0], Viewer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ianthe-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
