{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da4d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import napari\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "from scipy import stats\n",
    "import skimage as ski\n",
    "import dask.dataframe as dd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from bioio import BioImage\n",
    "import bioio_tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320b4df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum number of pixels for a filament to be included in analysis\n",
    "min_pixels = 3\n",
    "\n",
    "# Minimum length (um) for a filament to be included in analysis.\n",
    "# Can select 2D, 3D, or both.\n",
    "min_length_2D = 0\n",
    "min_length_3D = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b75bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_coordinates(coordinate_string, tuple_format=False):\n",
    "\tcoords_str = coordinate_string[1:-1]\n",
    "\tcoord_list = []\n",
    "\tfor match in re.findall(r\"\\(.*?\\)\", coords_str):\n",
    "\t\tcoordinate = match[1:-1]\n",
    "\t\tcoord_list.append([float(coord) for coord in coordinate.split(\",\")])\n",
    "\tif tuple_format:\n",
    "\t\treturn [tuple(coord) for coord in coord_list]\n",
    "\treturn np.array(coord_list)\n",
    "\n",
    "def parse_list(list_string):\n",
    "\tlist_str = list_string[1:-1]\n",
    "\treturn [int(item) for item in list_str.split(\",\")]\n",
    "\n",
    "def get_distance(point_array, dims=3):\n",
    "\tif dims == 2:\n",
    "\t\tpoint_array = point_array[:, :2]\n",
    "\tdiffs = np.diff(point_array, axis=0)\n",
    "\tdistances = np.linalg.norm(diffs, axis=1)\n",
    "\treturn np.sum(distances)\n",
    "\n",
    "def get_radians_2D(p1, p2):\n",
    "\tradians = math.atan2(p2[1] - p1[1], p2[0] - p1[0])\n",
    "\tabsolute_radians = np.mod(radians, np.pi)\n",
    "\treturn absolute_radians\n",
    "\n",
    "\n",
    "def get_average_radians(point_array, spacer=5):\n",
    "\tif spacer >= len(point_array):\n",
    "\t\tspacer = len(point_array) - 1\n",
    "\txdiff = point_array[spacer:, 0] - point_array[:-spacer, 0]\n",
    "\tydiff = point_array[spacer:, 1] - point_array[:-spacer, 1]\n",
    "\tradians = np.arctan2(ydiff, xdiff)\n",
    "\tmean_radians = stats.circmean(radians)\n",
    "\tabsolute_radians = np.mod(mean_radians, np.pi)\n",
    "\treturn absolute_radians\n",
    "\n",
    "def compareAngles(a, b):\n",
    "\tdelta = ((b - a + 180.0) % 360.0) - 180.0\n",
    "\treturn np.abs(delta)\n",
    "\n",
    "def get_branch_angles(df, vertices_col, angle_col, new_col):\n",
    "\t# Keep original order/id\n",
    "\ttmp = df.reset_index().rename(columns={\"index\": \"_idx\"})\n",
    "\n",
    "\t# 1) One vertex per row\n",
    "\tex = tmp[[\"_idx\", angle_col, vertices_col]].explode(vertices_col, ignore_index=True)\n",
    "\n",
    "\t# 2) Self-join on vertex to find neighbors sharing any vertex\n",
    "\tpairs = ex.merge(ex, on=vertices_col, how=\"inner\", suffixes=(\"_src\", \"_tgt\"))\n",
    "\n",
    "\t# 3) Drop self-pairs and (optionally) duplicate pairs that arise if two rows share multiple vertices\n",
    "\tpairs = pairs[pairs[\"_idx_src\"] != pairs[\"_idx_tgt\"]]\n",
    "\tpairs = pairs.drop_duplicates([\"_idx_src\", \"_idx_tgt\"])\n",
    "\n",
    "\t# 4) Vectorized angle diffs from src->tgt\n",
    "\tdiffs = compareAngles(pairs[f\"{angle_col}_src\"].to_numpy(),\n",
    "\t\t\t\t\t\t   pairs[f\"{angle_col}_tgt\"].to_numpy())\n",
    "\tpairs = pairs.assign(diff=diffs)\n",
    "\n",
    "\t# 5) Keep strictly positive diffs, aggregate per source row as list\n",
    "\tpairs = pairs[pairs[\"diff\"] > 0]\n",
    "\tagg = pairs.groupby(\"_idx_src\")[\"diff\"].apply(list).rename(new_col)\n",
    "\n",
    "\t# 6) Join back to original frame\n",
    "\tout = tmp.join(agg, on=\"_idx\").drop(columns=[\"_idx\"])\n",
    "\n",
    "\t# Preserve original index/columns order\n",
    "\tout.index = df.index\n",
    "\treturn out\n",
    "\n",
    "def get_residuals(point_array):\n",
    "\tNDModel = ski.measure.LineModelND()\n",
    "\tJustStartAndEnd = np.stack((point_array[0, :], point_array[-1, :]))\n",
    "\tNDModel.estimate(JustStartAndEnd)\n",
    "\treturn np.mean(NDModel.residuals(point_array))\n",
    "\n",
    "def get_curvature(coords, spacing=1):\n",
    "\tn = coords.shape[0]\n",
    "\tif n < (3 * spacing):\n",
    "\t\treturn np.nan, np.nan\n",
    "\txy = coords[:, :2]\n",
    "\n",
    "\tcurv = []\n",
    "\tfor i in range(spacing, n - spacing):\n",
    "\t\te1, p, e2 = xy[i - spacing], xy[i], xy[i + spacing]\n",
    "\t\tv1, v2 = p - e1, e2 - p\n",
    "\t\tl1, l2, l3 = np.linalg.norm(v1), np.linalg.norm(v2), np.linalg.norm(e2 - e1)\n",
    "\t\tdenom = l1 * l2 * l3\n",
    "\t\tif denom == 0:\n",
    "\t\t\tcontinue\n",
    "\t\tcross_z = v1[0] * v2[1] - v1[1] * v2[0]\n",
    "\t\tk = (abs(cross_z) / denom) * np.sign(cross_z)\n",
    "\t\tcurv.append(k)\n",
    "\n",
    "\tif not curv:\n",
    "\t\treturn np.nan, np.nan\n",
    "\n",
    "\tcurv = np.array(curv)\n",
    "\taccumulated_curv = np.nanmean(np.abs(curv))\n",
    "\tnet_curv = np.abs(np.nanmean(curv))\n",
    "\treturn accumulated_curv, net_curv\n",
    "\n",
    "def render_filaments(df, filename, viewer):\n",
    "\tonefile = df[df[\"Filename\"] == filename]\n",
    "\timp = BioImage(onefile[\"Filename\"][0], reader=bioio_tifffile.Reader)\n",
    "\timage_data = imp.chunk[0, 0, :, :, :]\n",
    "\tscale = (imp.physical_pixel_sizes.Z, imp.physical_pixel_sizes.Y, imp.physical_pixel_sizes.X)\n",
    "\tviewer.add_image(image_chunk, scale=scale)\n",
    "\tcoordlist = onefile[\"Coordinates (um)\"].tolist()\n",
    "\tlabel_img = np.zeros(image_chunk.shape, dtype=np.uint16)\n",
    "\tcoordlist = [np.round(coord[:, ::-1]/scale).astype(int) for coord in coordlist]\n",
    "\tfor label_id, coord in enumerate(coordlist):\n",
    "\t\tfor index in range(coord.shape[0]):\n",
    "\t\t\tlabel_img[(coord[index, 0], coord[index, 1], coord[index, 2])] = label_id + 1\n",
    "\tviewer.add_labels(label_img, scale=scale)\n",
    "\n",
    "def transform_file(src_path, dst_path):\n",
    "    total_bytes = os.path.getsize(src_path)\n",
    "    with open(src_path, 'r', encoding='utf-8') as src, \\\n",
    "         open(dst_path, 'w', encoding='utf-8') as dst, \\\n",
    "        tqdm(total=total_bytes, unit='B', unit_scale=True, desc=\"Processing\") as pbar:\n",
    "        for line in src:\n",
    "            pbar.update(len(line.encode('utf-8')))\n",
    "            line = line.replace(',[' , ',\"[').replace('],', ']\",')\n",
    "            dst.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bea9e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input \"Per_Filament_Coordinates.csv\" filepath here\n",
    "folder_path = r\"D:\\Data\\Durham\"\n",
    "filename = \"Per_Filament_Coordinates_Ianthe.csv\"\n",
    "savefilename = \"Per_Filament_Processed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63dcde3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|█████████▉| 36.3G/36.3G [04:57<00:00, 122MB/s] \n"
     ]
    }
   ],
   "source": [
    "transform_file(os.path.join(folder_path, filename), os.path.join(folder_path, \"Fixed_\" + filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c661ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = os.path.join(folder_path, \"Fixed_\" + filename)\n",
    "data = pd.read_csv(datafile, on_bad_lines=\"warn\", chunksize=10000000)\n",
    "buffer = None\n",
    "chunksProcessed = 0\n",
    "for chunk in data:\n",
    "\tif buffer is not None:\n",
    "\t\tchunk = pd.concat([buffer, chunk], ignore_index=True)\n",
    "\t# chunk[\"Filename\"] = chunk[\"Filename\"].astype(\"category\")\n",
    "\tprint (datetime.now().strftime(\"%H:%M:%S\"),chunk.memory_usage(index=True).sum()/1024**3, \"GB\")\n",
    "\tlast_filename = chunk[\"Filename\"].iloc[-1]\n",
    "\tbuffer = chunk[chunk[\"Filename\"] == last_filename].copy()\n",
    "\tchunk = chunk.drop(chunk[chunk[\"Filename\"] == last_filename].index)\n",
    "\n",
    "\tprint(datetime.now().strftime(\"%H:%M:%S\"), \"Parsing Coordinates...\")\n",
    "\t# Parses coordinate strings into numpy arrays\n",
    "\tchunk[\"Coordinates (um)\"] = chunk[\"Coordinates (um)\"].apply(parse_coordinates)\n",
    "\tchunk[\"Verticies\"] = chunk[\"Verticies\"].apply(parse_coordinates, tuple_format=True)\n",
    "\t# Parses vertex locations into lists\n",
    "\tchunk[\"Vertex Locations\"] = chunk[\"Vertex Locations\"].apply(parse_list)\n",
    "\tprint(datetime.now().strftime(\"%H:%M:%S\"), \"Filtering for number of pixels...\")\n",
    "\t# Getting number of pixels in filament\n",
    "\tchunk[\"Num. Pixels\"] = chunk[\"Coordinates (um)\"].apply(lambda coords: len(coords))\n",
    "\t# Filtering by minimum pixels\n",
    "\tchunk = chunk[chunk[\"Num. Pixels\"] >= min_pixels]\n",
    "\n",
    "\tprint(datetime.now().strftime(\"%H:%M:%S\"), \"Calculating lengths...\")\n",
    "\t# Getting length of filament in 2D\n",
    "\tchunk[\"Length 2D (um)\"] = chunk[\"Coordinates (um)\"].apply(get_distance, dims=2)\n",
    "\t# Filtering by minimum lengths in 2D\n",
    "\tchunk = chunk[chunk[\"Length 2D (um)\"] >= min_length_2D]\n",
    "\t# Getting length of filament in 3D\n",
    "\tchunk[\"Length 3D (um)\"] = chunk[\"Coordinates (um)\"].apply(get_distance, dims=3)\n",
    "\t# Filtering by minimum lengths in 3D\n",
    "\tchunk = chunk[chunk[\"Length 3D (um)\"] >= min_length_3D]\n",
    "\n",
    "\tprint(datetime.now().strftime(\"%H:%M:%S\"), \"Calculating angles...\")\n",
    "\t# Gets angles by getting angle between points spaced by 'spacer' value and averaging them\n",
    "\tchunk[\"Average Angle (radians)\"] = chunk[\"Coordinates (um)\"].apply(get_average_radians, spacer=5)\n",
    "\tchunk[\"Average Angle (degrees)\"] = np.degrees(chunk[\"Average Angle (radians)\"])\n",
    "\t# Gets angle between the first and last point of the filament\n",
    "\tchunk[\"End to End Angle (radians)\"] = chunk[\"Coordinates (um)\"].apply(lambda coords: get_radians_2D(coords[0], coords[-1]))\n",
    "\tchunk[\"End to End Angle (degrees)\"] = np.degrees(chunk[\"End to End Angle (radians)\"])\n",
    "\n",
    "\tprint(datetime.now().strftime(\"%H:%M:%S\"), \"Calculating branch angles...\")\n",
    "\t# Gets branch angles by finding filaments that share verticies and comparing their average angles\n",
    "\tresults = []\n",
    "\tfor (fname, chan), subset in chunk.groupby([\"Filename\", \"Channel\"]):\n",
    "\t\tresults.append(get_branch_angles(subset, \"Verticies\", \"Average Angle (degrees)\", \"Branch Angles (degrees)\"))\n",
    "\tchunk = pd.concat(results)\n",
    "\n",
    "\tprint(datetime.now().strftime(\"%H:%M:%S\"), \"Calculating deviations...\")\n",
    "\t#  Gets the mean distance from a straight line between the endpoints of the filament\n",
    "\tchunk[\"Deviation (um)\"] = chunk[\"Coordinates (um)\"].apply(get_residuals)\n",
    "\n",
    "\tprint(datetime.now().strftime(\"%H:%M:%S\"), \"Calculating curvatures...\")\n",
    "\t# Gets curvature values\n",
    "\tchunk[[\"Accumulated Curvature\", \"Net Curvature\"]] = chunk[\"Coordinates (um)\"].apply(lambda coords: get_curvature(coords, spacing=1)).apply(pd.Series)\n",
    "\tchunksProcessed += 1\n",
    "\tprint(datetime.now().strftime(\"%H:%M:%S\"), \"Saving chunk\", chunksProcessed)\n",
    "\tchunk.to_csv(os.path.join(folder_path, savefilename), mode='a', header=not os.path.exists(os.path.join(folder_path, savefilename)), index=False)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3966b16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Filament ID</th>\n",
       "      <th>Coordinates (um)</th>\n",
       "      <th>Verticies</th>\n",
       "      <th>Vertex Locations</th>\n",
       "      <th>Num. Pixels</th>\n",
       "      <th>Length 2D (um)</th>\n",
       "      <th>Length 3D (um)</th>\n",
       "      <th>Average Angle (radians)</th>\n",
       "      <th>Average Angle (degrees)</th>\n",
       "      <th>End to End Angle (radians)</th>\n",
       "      <th>End to End Angle (degrees)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Filename, Channel, Filament ID, Coordinates (um), Verticies, Vertex Locations, Num. Pixels, Length 2D (um), Length 3D (um), Average Angle (radians), Average Angle (degrees), End to End Angle (radians), End to End Angle (degrees)]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "809954b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = databackup.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaff53a",
   "metadata": {},
   "source": [
    "This next cell saves the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e0b9525",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(os.path.join(folder_path, \"Per_Filament_Coordinates_Analyzed.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad1e70",
   "metadata": {},
   "source": [
    "This next cell can load in previously saved outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea9e0f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(os.path.join(folder_path, \"Per_Filament_Coordinates_Analyzed.pkl\"))\n",
    "databackup = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab6750",
   "metadata": {},
   "source": [
    "This next cell opens up napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92962a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "Viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325168f",
   "metadata": {},
   "source": [
    "This next cell allows you to view a labelled image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16445e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_filaments(data, data[\"Filename\"][0], Viewer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
